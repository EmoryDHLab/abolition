{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arshi\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import csv\n",
    "import node2vec\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "documents = []\n",
    "names = []\n",
    "edges = []\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "with open('all_names.csv') as all_names:\n",
    "    name_reader = csv.reader(all_names)\n",
    "    for row in name_reader:\n",
    "        documents.append(row[0])\n",
    "        for name in row[1:]:\n",
    "            names.append(name)\n",
    "            edges.append((row[0], name))\n",
    "            \n",
    "B.add_nodes_from(documents, bipartite=0)\n",
    "B.add_nodes_from(names, bipartite=1)\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5273\n",
      "1048\n"
     ]
    }
   ],
   "source": [
    "print(len(B.nodes))\n",
    "one_edge_nodes = []\n",
    "for node in B.nodes:\n",
    "    if len([n for n in B[node]]) <= 1:\n",
    "        one_edge_nodes.append(node)\n",
    "        \n",
    "B.remove_nodes_from(one_edge_nodes)\n",
    "print(len(B.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "## Girvan Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import *\n",
    "# either import or make your own like the one above\n",
    "\n",
    "bipartite_graph = Graph.Read_GML('bipartite.gml')\n",
    "\n",
    "# Girvan Newman clusters\n",
    "gn_clusters = bipartite_graph.community_edge_betweenness().as_clustering()\n",
    "# plot(gn_clusters)\n",
    "writer = csv.writer(open(\"gn_clusters.csv\", \"w\", newline=''))\n",
    "writer.writerow([\"cluster\", \"members\"])\n",
    "count = 0\n",
    "for cluster in gn_clusters:\n",
    "    members = [bipartite_graph.vs[member][\"label\"] for member in cluster]\n",
    "    writer.writerow([count] + members)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clustering with 1048 elements and 11 clusters'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Louvain clusters\n",
    "louvain_clusters = bipartite_graph.community_multilevel()\n",
    "# plot(louvain_clusters)\n",
    "writer = csv.writer(open(\"louvain_clusters.csv\", \"w\", newline=''))\n",
    "writer.writerow([\"cluster\", \"members\"])\n",
    "count = 0\n",
    "for cluster in louvain_clusters:\n",
    "    members = [bipartite_graph.vs[member][\"label\"] for member in cluster]\n",
    "    writer.writerow([count] + members)\n",
    "    count += 1\n",
    "louvain_clusters.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILES\n",
    "EMBEDDING_FILENAME = './bipartite.emb'\n",
    "EMBEDDING_MODEL_FILENAME = './bipartite.model'\n",
    "\n",
    "# Precompute probabilities and generate walks\n",
    "node2vec = Node2Vec(B, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "\n",
    "# Embed\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Any keywords acceptable by gensim.Word2Vec can be passed,\n",
    "# `diemnsions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "\n",
    "# Look for most similar nodes\n",
    "print(model.wv.most_similar('2'))  # Output node names are always strings\n",
    "\n",
    "# Save embeddings for later use\n",
    "model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n",
    "\n",
    "# Save model for later use\n",
    "model.save(EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the word2vec/node2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('bipartite.model')\n",
    "X = model.wv[model.wv.vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing a word2vec model (with words)\n",
    "[Reference here](https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "tokens = []\n",
    "\n",
    "for word in model.wv.vocab:\n",
    "    tokens.append(model.wv[word])\n",
    "    labels.append(word)\n",
    "\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "plt.figure(figsize=(16, 16)) \n",
    "\n",
    "for i in range(len(x)):\n",
    "    plt.scatter(x[i],y[i])\n",
    "    plt.annotate(labels[i],\n",
    "                 xy=(x[i], y[i]),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
