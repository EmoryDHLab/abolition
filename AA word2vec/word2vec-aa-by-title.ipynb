{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic logging setup\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"accessible-v4.0-small\"\n",
    "\n",
    "prev_words = 0\n",
    "total_words = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyArticles(object):\n",
    "    def __init__(self, base_dir, cur_paper):\n",
    "        self.base_dir = base_dir\n",
    "        self.cur_paper = cur_paper\n",
    "                                             \n",
    "    def __iter__(self):\n",
    "        logging.info(\"Opening paper {0}\".format(self.cur_paper))\n",
    "        \n",
    "        issues = os.listdir(base_dir + \"/\" + self.cur_paper)\n",
    "        \n",
    "        for issue in issues:\n",
    "            if not issue.startswith('.'):\n",
    "               # logging.info(\"Opening issue {0}\".format(issue))\n",
    "                articles = os.listdir(base_dir + \"/\" + self.cur_paper + \"/\" + issue)\n",
    "\n",
    "                for article in articles:\n",
    "                    if not article.startswith('.'):\n",
    "                        # logging.info(\"Reading article {0}\".format(article))\n",
    "                            \n",
    "                        articleFile = open(base_dir + \"/\" + self.cur_paper + \"/\" + issue + \"/\" + article, \"r\")\n",
    "                        articleText = articleFile.read()\n",
    "                        articleFile.close()\n",
    "                    \n",
    "                        # create word list for the article; could refine to be sentences later \n",
    "                        articleWords = []\n",
    "               \n",
    "                        # ignore single-char words and words with numbers in them                        \n",
    "                        for word in re.split('\\W+', articleText):\n",
    "                            if len(word) > 1 and not any(char.isdigit() for char in word):\n",
    "                                # lowercase and add to list\n",
    "                                articleWords.append(word.lower())\n",
    "                                        \n",
    "                        yield articleWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DouglassMonthly docs into the list of list formas\n",
    "cur_paper = \"DouglassMonthly\"\n",
    "articles = MyArticles(base_dir, cur_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:06:39,328 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:06:39,329 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:39,332 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:06:41,113 : INFO : collected 105681 word types from a corpus of 1233295 raw words and 1718 sentences\n",
      "2019-01-16 22:06:41,113 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:06:41,160 : INFO : min_count=5 retains 14580 unique words (13% of original 105681, drops 91101)\n",
      "2019-01-16 22:06:41,161 : INFO : min_count=5 leaves 1110087 word corpus (90% of original 1233295, drops 123208)\n",
      "2019-01-16 22:06:41,193 : INFO : deleting the raw counts dictionary of 105681 items\n",
      "2019-01-16 22:06:41,196 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2019-01-16 22:06:41,197 : INFO : downsampling leaves estimated 807646 word corpus (72.8% of prior 1110087)\n",
      "2019-01-16 22:06:41,232 : INFO : estimated required memory for 14580 words and 100 dimensions: 18954000 bytes\n",
      "2019-01-16 22:06:41,232 : INFO : resetting layer weights\n",
      "2019-01-16 22:06:41,361 : INFO : training model with 10 workers on 14580 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:06:41,364 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:42,367 : INFO : EPOCH 1 - PROGRESS: at 48.08% examples, 400945 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:43,338 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:06:43,339 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:06:43,339 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:06:43,342 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:06:43,343 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:06:43,344 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:06:43,349 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:06:43,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:06:43,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:06:43,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:06:43,352 : INFO : EPOCH - 1 : training on 1233295 raw words (800375 effective words) took 2.0s, 402569 effective words/s\n",
      "2019-01-16 22:06:43,355 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:44,360 : INFO : EPOCH 2 - PROGRESS: at 47.32% examples, 390764 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:45,365 : INFO : EPOCH 2 - PROGRESS: at 98.72% examples, 393359 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:45,375 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:06:45,376 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:06:45,377 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:06:45,378 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:06:45,379 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:06:45,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:06:45,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:06:45,382 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:06:45,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:06:45,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:06:45,385 : INFO : EPOCH - 2 : training on 1233295 raw words (799953 effective words) took 2.0s, 394283 effective words/s\n",
      "2019-01-16 22:06:45,389 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:46,406 : INFO : EPOCH 3 - PROGRESS: at 48.08% examples, 395543 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:47,390 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:06:47,391 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:06:47,392 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:06:47,393 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:06:47,394 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:06:47,395 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:06:47,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:06:47,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:06:47,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:06:47,398 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:06:47,398 : INFO : EPOCH - 3 : training on 1233295 raw words (800497 effective words) took 2.0s, 398473 effective words/s\n",
      "2019-01-16 22:06:47,403 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:48,420 : INFO : EPOCH 4 - PROGRESS: at 48.89% examples, 400122 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:49,366 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:06:49,367 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:06:49,368 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:06:49,368 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:06:49,370 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:06:49,371 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:06:49,372 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:06:49,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:06:49,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:06:49,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:06:49,374 : INFO : EPOCH - 4 : training on 1233295 raw words (800022 effective words) took 2.0s, 405985 effective words/s\n",
      "2019-01-16 22:06:49,379 : INFO : Opening paper DouglassMonthly\n",
      "2019-01-16 22:06:50,391 : INFO : EPOCH 5 - PROGRESS: at 47.32% examples, 387669 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:51,392 : INFO : EPOCH 5 - PROGRESS: at 98.72% examples, 392589 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:06:51,402 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:06:51,403 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:06:51,404 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:06:51,405 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:06:51,406 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:06:51,407 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:06:51,408 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:06:51,409 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:06:51,410 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:06:51,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:06:51,412 : INFO : EPOCH - 5 : training on 1233295 raw words (800174 effective words) took 2.0s, 393608 effective words/s\n",
      "2019-01-16 22:06:51,412 : INFO : training on a 6166475 raw words (4001021 effective words) took 10.1s, 398076 effective words/s\n",
      "2019-01-16 22:06:51,415 : INFO : saving Word2Vec object under DouglassMonthly-w2v-model, separately None\n",
      "2019-01-16 22:06:51,416 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:06:51,417 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:06:51,534 : INFO : saved DouglassMonthly-w2v-model\n"
     ]
    }
   ],
   "source": [
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=10) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:09:17,904 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:09:17,905 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:09:17,908 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:09:35,529 : INFO : PROGRESS: at sentence #10000, processed 12438832 words, keeping 115416 word types\n",
      "2019-01-16 22:09:43,344 : INFO : collected 137965 word types from a corpus of 18074868 raw words and 14430 sentences\n",
      "2019-01-16 22:09:43,345 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:09:43,475 : INFO : min_count=5 retains 48558 unique words (35% of original 137965, drops 89407)\n",
      "2019-01-16 22:09:43,476 : INFO : min_count=5 leaves 17938038 word corpus (99% of original 18074868, drops 136830)\n",
      "2019-01-16 22:09:43,577 : INFO : deleting the raw counts dictionary of 137965 items\n",
      "2019-01-16 22:09:43,580 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2019-01-16 22:09:43,582 : INFO : downsampling leaves estimated 13762113 word corpus (76.7% of prior 17938038)\n",
      "2019-01-16 22:09:43,694 : INFO : estimated required memory for 48558 words and 100 dimensions: 63125400 bytes\n",
      "2019-01-16 22:09:43,695 : INFO : resetting layer weights\n",
      "2019-01-16 22:09:44,106 : INFO : training model with 10 workers on 48558 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:09:44,109 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:09:45,110 : INFO : EPOCH 1 - PROGRESS: at 3.56% examples, 455639 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:46,117 : INFO : EPOCH 1 - PROGRESS: at 6.86% examples, 458966 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:47,130 : INFO : EPOCH 1 - PROGRESS: at 10.49% examples, 462157 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:48,132 : INFO : EPOCH 1 - PROGRESS: at 13.69% examples, 462059 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:49,140 : INFO : EPOCH 1 - PROGRESS: at 17.23% examples, 461648 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:50,152 : INFO : EPOCH 1 - PROGRESS: at 20.74% examples, 463179 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:51,153 : INFO : EPOCH 1 - PROGRESS: at 23.92% examples, 463162 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:52,158 : INFO : EPOCH 1 - PROGRESS: at 27.36% examples, 463339 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:09:53,160 : INFO : EPOCH 1 - PROGRESS: at 30.64% examples, 464283 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:54,163 : INFO : EPOCH 1 - PROGRESS: at 34.03% examples, 464539 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:55,173 : INFO : EPOCH 1 - PROGRESS: at 37.62% examples, 464841 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:56,185 : INFO : EPOCH 1 - PROGRESS: at 40.74% examples, 463239 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:57,190 : INFO : EPOCH 1 - PROGRESS: at 43.92% examples, 461844 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:58,195 : INFO : EPOCH 1 - PROGRESS: at 47.01% examples, 460513 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:09:59,200 : INFO : EPOCH 1 - PROGRESS: at 50.45% examples, 460968 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:00,211 : INFO : EPOCH 1 - PROGRESS: at 54.02% examples, 460196 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:01,211 : INFO : EPOCH 1 - PROGRESS: at 57.58% examples, 460096 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:02,223 : INFO : EPOCH 1 - PROGRESS: at 60.88% examples, 459738 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:03,234 : INFO : EPOCH 1 - PROGRESS: at 63.83% examples, 456878 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:04,248 : INFO : EPOCH 1 - PROGRESS: at 66.85% examples, 453924 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:05,263 : INFO : EPOCH 1 - PROGRESS: at 70.00% examples, 451978 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:06,275 : INFO : EPOCH 1 - PROGRESS: at 73.07% examples, 452709 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:07,288 : INFO : EPOCH 1 - PROGRESS: at 76.91% examples, 453313 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:08,301 : INFO : EPOCH 1 - PROGRESS: at 80.06% examples, 454111 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:09,322 : INFO : EPOCH 1 - PROGRESS: at 83.37% examples, 453743 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:10,338 : INFO : EPOCH 1 - PROGRESS: at 86.87% examples, 453903 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:11,348 : INFO : EPOCH 1 - PROGRESS: at 90.07% examples, 453978 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:12,353 : INFO : EPOCH 1 - PROGRESS: at 93.41% examples, 454424 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:13,354 : INFO : EPOCH 1 - PROGRESS: at 96.83% examples, 454803 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:14,355 : INFO : EPOCH 1 - PROGRESS: at 99.90% examples, 454451 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:14,368 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:10:14,369 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:10:14,370 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:10:14,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:10:14,372 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:10:14,373 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:10:14,373 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:10:14,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:10:14,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:10:14,389 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:10:14,389 : INFO : EPOCH - 1 : training on 18074868 raw words (13757823 effective words) took 30.3s, 454348 effective words/s\n",
      "2019-01-16 22:10:14,392 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:10:15,445 : INFO : EPOCH 2 - PROGRESS: at 3.53% examples, 426767 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:10:16,450 : INFO : EPOCH 2 - PROGRESS: at 6.48% examples, 420399 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:17,468 : INFO : EPOCH 2 - PROGRESS: at 9.42% examples, 406489 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:18,474 : INFO : EPOCH 2 - PROGRESS: at 12.65% examples, 419983 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:19,474 : INFO : EPOCH 2 - PROGRESS: at 16.10% examples, 429069 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:20,475 : INFO : EPOCH 2 - PROGRESS: at 19.75% examples, 435907 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:21,487 : INFO : EPOCH 2 - PROGRESS: at 22.81% examples, 436322 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:22,494 : INFO : EPOCH 2 - PROGRESS: at 26.15% examples, 440281 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:23,497 : INFO : EPOCH 2 - PROGRESS: at 29.40% examples, 444063 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:24,518 : INFO : EPOCH 2 - PROGRESS: at 33.06% examples, 446110 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:25,524 : INFO : EPOCH 2 - PROGRESS: at 36.57% examples, 448020 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:26,525 : INFO : EPOCH 2 - PROGRESS: at 39.93% examples, 449925 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:27,533 : INFO : EPOCH 2 - PROGRESS: at 43.19% examples, 451321 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:28,538 : INFO : EPOCH 2 - PROGRESS: at 46.44% examples, 452832 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:29,548 : INFO : EPOCH 2 - PROGRESS: at 49.88% examples, 453922 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:30,559 : INFO : EPOCH 2 - PROGRESS: at 53.58% examples, 455060 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:31,563 : INFO : EPOCH 2 - PROGRESS: at 57.14% examples, 455355 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:32,564 : INFO : EPOCH 2 - PROGRESS: at 60.55% examples, 455549 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:33,565 : INFO : EPOCH 2 - PROGRESS: at 63.93% examples, 456344 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:34,566 : INFO : EPOCH 2 - PROGRESS: at 67.48% examples, 457018 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:35,566 : INFO : EPOCH 2 - PROGRESS: at 70.88% examples, 457771 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:10:36,573 : INFO : EPOCH 2 - PROGRESS: at 74.12% examples, 458090 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:37,578 : INFO : EPOCH 2 - PROGRESS: at 77.91% examples, 458904 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:38,585 : INFO : EPOCH 2 - PROGRESS: at 81.14% examples, 459377 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:39,590 : INFO : EPOCH 2 - PROGRESS: at 84.44% examples, 459778 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:40,598 : INFO : EPOCH 2 - PROGRESS: at 87.88% examples, 460142 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:41,601 : INFO : EPOCH 2 - PROGRESS: at 91.35% examples, 460530 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:42,614 : INFO : EPOCH 2 - PROGRESS: at 94.84% examples, 460925 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:43,621 : INFO : EPOCH 2 - PROGRESS: at 97.93% examples, 460506 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:44,258 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:10:44,259 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:10:44,259 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:10:44,260 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:10:44,261 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:10:44,262 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:10:44,263 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:10:44,264 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:10:44,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:10:44,268 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:10:44,269 : INFO : EPOCH - 2 : training on 18074868 raw words (13758414 effective words) took 29.9s, 460508 effective words/s\n",
      "2019-01-16 22:10:44,273 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:10:45,280 : INFO : EPOCH 3 - PROGRESS: at 3.60% examples, 460500 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:46,283 : INFO : EPOCH 3 - PROGRESS: at 6.75% examples, 451581 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:47,301 : INFO : EPOCH 3 - PROGRESS: at 10.38% examples, 456304 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:48,302 : INFO : EPOCH 3 - PROGRESS: at 13.61% examples, 457771 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:49,316 : INFO : EPOCH 3 - PROGRESS: at 17.10% examples, 458090 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:50,319 : INFO : EPOCH 3 - PROGRESS: at 20.46% examples, 455408 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:51,325 : INFO : EPOCH 3 - PROGRESS: at 23.55% examples, 455812 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:52,330 : INFO : EPOCH 3 - PROGRESS: at 27.11% examples, 457647 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:53,333 : INFO : EPOCH 3 - PROGRESS: at 30.30% examples, 459426 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:54,335 : INFO : EPOCH 3 - PROGRESS: at 33.85% examples, 460968 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:55,345 : INFO : EPOCH 3 - PROGRESS: at 37.46% examples, 461973 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:56,357 : INFO : EPOCH 3 - PROGRESS: at 40.73% examples, 462079 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:57,358 : INFO : EPOCH 3 - PROGRESS: at 43.94% examples, 462181 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:58,366 : INFO : EPOCH 3 - PROGRESS: at 47.18% examples, 462216 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:10:59,369 : INFO : EPOCH 3 - PROGRESS: at 50.69% examples, 462920 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:00,378 : INFO : EPOCH 3 - PROGRESS: at 54.17% examples, 461808 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:01,380 : INFO : EPOCH 3 - PROGRESS: at 56.85% examples, 455333 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:02,381 : INFO : EPOCH 3 - PROGRESS: at 59.80% examples, 451345 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:03,402 : INFO : EPOCH 3 - PROGRESS: at 63.08% examples, 451149 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:04,409 : INFO : EPOCH 3 - PROGRESS: at 66.39% examples, 451342 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:05,425 : INFO : EPOCH 3 - PROGRESS: at 70.00% examples, 451993 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:06,433 : INFO : EPOCH 3 - PROGRESS: at 72.52% examples, 449607 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:07,434 : INFO : EPOCH 3 - PROGRESS: at 75.92% examples, 448164 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:08,436 : INFO : EPOCH 3 - PROGRESS: at 78.72% examples, 446385 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:09,441 : INFO : EPOCH 3 - PROGRESS: at 81.99% examples, 446648 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:10,447 : INFO : EPOCH 3 - PROGRESS: at 85.14% examples, 446594 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:11,447 : INFO : EPOCH 3 - PROGRESS: at 88.49% examples, 447085 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:12,464 : INFO : EPOCH 3 - PROGRESS: at 91.61% examples, 445590 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:13,477 : INFO : EPOCH 3 - PROGRESS: at 94.44% examples, 443786 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:14,487 : INFO : EPOCH 3 - PROGRESS: at 97.69% examples, 444060 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:15,219 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:11:15,221 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:11:15,222 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:11:15,223 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:11:15,224 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:11:15,225 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:11:15,226 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:11:15,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:11:15,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:11:15,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:11:15,232 : INFO : EPOCH - 3 : training on 18074868 raw words (13757837 effective words) took 31.0s, 444400 effective words/s\n",
      "2019-01-16 22:11:15,236 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:11:16,252 : INFO : EPOCH 4 - PROGRESS: at 3.60% examples, 456159 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:17,254 : INFO : EPOCH 4 - PROGRESS: at 6.86% examples, 456581 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:18,261 : INFO : EPOCH 4 - PROGRESS: at 10.38% examples, 456769 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:19,274 : INFO : EPOCH 4 - PROGRESS: at 13.12% examples, 441829 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:20,277 : INFO : EPOCH 4 - PROGRESS: at 16.10% examples, 432692 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:21,289 : INFO : EPOCH 4 - PROGRESS: at 19.31% examples, 430086 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:22,300 : INFO : EPOCH 4 - PROGRESS: at 22.52% examples, 432313 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:23,303 : INFO : EPOCH 4 - PROGRESS: at 25.87% examples, 437027 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:24,312 : INFO : EPOCH 4 - PROGRESS: at 29.12% examples, 441350 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:25,323 : INFO : EPOCH 4 - PROGRESS: at 32.70% examples, 444025 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:26,328 : INFO : EPOCH 4 - PROGRESS: at 36.35% examples, 446516 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:27,334 : INFO : EPOCH 4 - PROGRESS: at 39.67% examples, 448373 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:28,335 : INFO : EPOCH 4 - PROGRESS: at 42.95% examples, 450452 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:29,344 : INFO : EPOCH 4 - PROGRESS: at 46.22% examples, 451880 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:30,360 : INFO : EPOCH 4 - PROGRESS: at 49.63% examples, 452994 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:11:31,364 : INFO : EPOCH 4 - PROGRESS: at 53.28% examples, 454032 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:32,370 : INFO : EPOCH 4 - PROGRESS: at 56.85% examples, 454681 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:33,371 : INFO : EPOCH 4 - PROGRESS: at 60.39% examples, 455284 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:34,381 : INFO : EPOCH 4 - PROGRESS: at 63.67% examples, 454936 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:35,397 : INFO : EPOCH 4 - PROGRESS: at 67.15% examples, 455161 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:36,411 : INFO : EPOCH 4 - PROGRESS: at 70.64% examples, 456082 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:37,416 : INFO : EPOCH 4 - PROGRESS: at 73.90% examples, 456627 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:38,439 : INFO : EPOCH 4 - PROGRESS: at 77.65% examples, 456941 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:39,442 : INFO : EPOCH 4 - PROGRESS: at 80.76% examples, 457231 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:40,445 : INFO : EPOCH 4 - PROGRESS: at 84.08% examples, 457445 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:41,448 : INFO : EPOCH 4 - PROGRESS: at 87.46% examples, 457511 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:42,453 : INFO : EPOCH 4 - PROGRESS: at 90.87% examples, 458055 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:43,453 : INFO : EPOCH 4 - PROGRESS: at 94.28% examples, 458545 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:44,455 : INFO : EPOCH 4 - PROGRESS: at 97.64% examples, 458827 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:45,196 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:11:45,197 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:11:45,199 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:11:45,199 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:11:45,200 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:11:45,201 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:11:45,202 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:11:45,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:11:45,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:11:45,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:11:45,209 : INFO : EPOCH - 4 : training on 18074868 raw words (13759100 effective words) took 30.0s, 459053 effective words/s\n",
      "2019-01-16 22:11:45,213 : INFO : Opening paper FrankLesliesWeekly\n",
      "2019-01-16 22:11:46,216 : INFO : EPOCH 5 - PROGRESS: at 3.60% examples, 461849 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:47,229 : INFO : EPOCH 5 - PROGRESS: at 6.99% examples, 464635 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:48,235 : INFO : EPOCH 5 - PROGRESS: at 10.59% examples, 466484 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:49,240 : INFO : EPOCH 5 - PROGRESS: at 13.79% examples, 463461 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:50,251 : INFO : EPOCH 5 - PROGRESS: at 17.33% examples, 463905 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:51,251 : INFO : EPOCH 5 - PROGRESS: at 20.82% examples, 465752 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:52,254 : INFO : EPOCH 5 - PROGRESS: at 24.04% examples, 466040 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:53,268 : INFO : EPOCH 5 - PROGRESS: at 27.49% examples, 466449 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:54,285 : INFO : EPOCH 5 - PROGRESS: at 30.81% examples, 466236 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:55,289 : INFO : EPOCH 5 - PROGRESS: at 34.18% examples, 466259 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:56,304 : INFO : EPOCH 5 - PROGRESS: at 37.91% examples, 466946 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:57,307 : INFO : EPOCH 5 - PROGRESS: at 41.18% examples, 467313 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:58,325 : INFO : EPOCH 5 - PROGRESS: at 44.39% examples, 466699 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:11:59,327 : INFO : EPOCH 5 - PROGRESS: at 47.75% examples, 466478 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:00,335 : INFO : EPOCH 5 - PROGRESS: at 51.24% examples, 466763 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:01,355 : INFO : EPOCH 5 - PROGRESS: at 54.82% examples, 466870 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:02,357 : INFO : EPOCH 5 - PROGRESS: at 58.54% examples, 466763 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:03,366 : INFO : EPOCH 5 - PROGRESS: at 61.76% examples, 465492 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:04,366 : INFO : EPOCH 5 - PROGRESS: at 65.20% examples, 465323 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:05,371 : INFO : EPOCH 5 - PROGRESS: at 68.46% examples, 464420 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:06,377 : INFO : EPOCH 5 - PROGRESS: at 71.66% examples, 463996 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:07,384 : INFO : EPOCH 5 - PROGRESS: at 75.00% examples, 463915 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:08,388 : INFO : EPOCH 5 - PROGRESS: at 78.51% examples, 463564 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:09,390 : INFO : EPOCH 5 - PROGRESS: at 81.83% examples, 463347 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:10,391 : INFO : EPOCH 5 - PROGRESS: at 85.02% examples, 463156 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:11,403 : INFO : EPOCH 5 - PROGRESS: at 88.31% examples, 463146 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:12,403 : INFO : EPOCH 5 - PROGRESS: at 91.84% examples, 463259 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:13,413 : INFO : EPOCH 5 - PROGRESS: at 95.20% examples, 463335 words/s, in_qsize 1, out_qsize 1\n",
      "2019-01-16 22:12:14,420 : INFO : EPOCH 5 - PROGRESS: at 98.44% examples, 463304 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:14,903 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:12:14,904 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:12:14,904 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:12:14,905 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:12:14,906 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:12:14,907 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:12:14,908 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:12:14,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:12:14,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:12:14,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:12:14,914 : INFO : EPOCH - 5 : training on 18074868 raw words (13759625 effective words) took 29.7s, 463268 effective words/s\n",
      "2019-01-16 22:12:14,915 : INFO : training on a 90374340 raw words (68792799 effective words) took 150.8s, 456157 effective words/s\n",
      "2019-01-16 22:12:14,918 : INFO : saving Word2Vec object under FrankLesliesWeekly-w2v-model, separately None\n",
      "2019-01-16 22:12:14,919 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:12:14,920 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:12:15,467 : INFO : saved FrankLesliesWeekly-w2v-model\n"
     ]
    }
   ],
   "source": [
    "# get FrankLesliesWeekly docs into the list of list formas\n",
    "cur_paper = \"FrankLesliesWeekly\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=10) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:12:23,384 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:12:23,384 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:12:23,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:12:31,315 : INFO : PROGRESS: at sentence #10000, processed 5604256 words, keeping 57600 word types\n",
      "2019-01-16 22:12:31,847 : INFO : collected 58840 word types from a corpus of 5955695 raw words and 10601 sentences\n",
      "2019-01-16 22:12:31,848 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:12:31,893 : INFO : min_count=5 retains 25130 unique words (42% of original 58840, drops 33710)\n",
      "2019-01-16 22:12:31,894 : INFO : min_count=5 leaves 5899851 word corpus (99% of original 5955695, drops 55844)\n",
      "2019-01-16 22:12:31,948 : INFO : deleting the raw counts dictionary of 58840 items\n",
      "2019-01-16 22:12:31,950 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-01-16 22:12:31,950 : INFO : downsampling leaves estimated 4366194 word corpus (74.0% of prior 5899851)\n",
      "2019-01-16 22:12:32,005 : INFO : estimated required memory for 25130 words and 100 dimensions: 32669000 bytes\n",
      "2019-01-16 22:12:32,005 : INFO : resetting layer weights\n",
      "2019-01-16 22:12:32,216 : INFO : training model with 10 workers on 25130 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:12:32,219 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:12:33,236 : INFO : EPOCH 1 - PROGRESS: at 10.78% examples, 430137 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:34,238 : INFO : EPOCH 1 - PROGRESS: at 19.89% examples, 432465 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:35,245 : INFO : EPOCH 1 - PROGRESS: at 28.72% examples, 430505 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:36,252 : INFO : EPOCH 1 - PROGRESS: at 39.61% examples, 429243 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:37,264 : INFO : EPOCH 1 - PROGRESS: at 49.88% examples, 429382 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:38,265 : INFO : EPOCH 1 - PROGRESS: at 59.37% examples, 432156 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:39,269 : INFO : EPOCH 1 - PROGRESS: at 70.43% examples, 434211 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:40,271 : INFO : EPOCH 1 - PROGRESS: at 80.38% examples, 435106 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:41,275 : INFO : EPOCH 1 - PROGRESS: at 90.93% examples, 436691 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:42,148 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:12:42,149 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:12:42,151 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:12:42,151 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:12:42,152 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:12:42,153 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:12:42,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:12:42,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:12:42,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:12:42,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:12:42,167 : INFO : EPOCH - 1 : training on 5955695 raw words (4342209 effective words) took 9.9s, 436521 effective words/s\n",
      "2019-01-16 22:12:42,170 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:12:43,178 : INFO : EPOCH 2 - PROGRESS: at 10.91% examples, 440624 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:44,180 : INFO : EPOCH 2 - PROGRESS: at 19.72% examples, 429817 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:45,186 : INFO : EPOCH 2 - PROGRESS: at 28.72% examples, 432034 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:46,187 : INFO : EPOCH 2 - PROGRESS: at 39.61% examples, 430823 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:47,196 : INFO : EPOCH 2 - PROGRESS: at 49.40% examples, 428350 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:48,201 : INFO : EPOCH 2 - PROGRESS: at 58.71% examples, 428718 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:49,215 : INFO : EPOCH 2 - PROGRESS: at 69.63% examples, 430528 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:50,219 : INFO : EPOCH 2 - PROGRESS: at 79.73% examples, 431675 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:51,228 : INFO : EPOCH 2 - PROGRESS: at 89.93% examples, 431182 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:52,234 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:12:52,235 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:12:52,236 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:12:52,237 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:12:52,238 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:12:52,238 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:12:52,239 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:12:52,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:12:52,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:12:52,245 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 430880 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:12:52,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:12:52,247 : INFO : EPOCH - 2 : training on 5955695 raw words (4341066 effective words) took 10.1s, 430808 effective words/s\n",
      "2019-01-16 22:12:52,251 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:12:53,259 : INFO : EPOCH 3 - PROGRESS: at 10.91% examples, 440883 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:54,270 : INFO : EPOCH 3 - PROGRESS: at 20.32% examples, 439242 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:55,274 : INFO : EPOCH 3 - PROGRESS: at 29.45% examples, 439690 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:56,285 : INFO : EPOCH 3 - PROGRESS: at 40.47% examples, 440539 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:57,298 : INFO : EPOCH 3 - PROGRESS: at 50.46% examples, 437062 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:58,305 : INFO : EPOCH 3 - PROGRESS: at 60.27% examples, 437012 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:12:59,311 : INFO : EPOCH 3 - PROGRESS: at 71.33% examples, 438324 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:00,313 : INFO : EPOCH 3 - PROGRESS: at 81.10% examples, 439226 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:01,334 : INFO : EPOCH 3 - PROGRESS: at 92.11% examples, 439586 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:02,117 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:13:02,117 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:13:02,118 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:13:02,119 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:13:02,120 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:13:02,121 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:13:02,122 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:13:02,123 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:13:02,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:13:02,127 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:02,128 : INFO : EPOCH - 3 : training on 5955695 raw words (4339695 effective words) took 9.9s, 439380 effective words/s\n",
      "2019-01-16 22:13:02,132 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:13:03,155 : INFO : EPOCH 4 - PROGRESS: at 11.03% examples, 439882 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:04,163 : INFO : EPOCH 4 - PROGRESS: at 21.00% examples, 446261 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:05,175 : INFO : EPOCH 4 - PROGRESS: at 30.29% examples, 446770 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:13:06,193 : INFO : EPOCH 4 - PROGRESS: at 41.40% examples, 447949 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:07,193 : INFO : EPOCH 4 - PROGRESS: at 51.25% examples, 446076 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:08,194 : INFO : EPOCH 4 - PROGRESS: at 61.00% examples, 442146 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:09,194 : INFO : EPOCH 4 - PROGRESS: at 72.18% examples, 442909 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:10,207 : INFO : EPOCH 4 - PROGRESS: at 81.75% examples, 441823 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:11,213 : INFO : EPOCH 4 - PROGRESS: at 92.73% examples, 441986 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:11,946 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:13:11,946 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:13:11,947 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:13:11,947 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:13:11,948 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:13:11,949 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:13:11,950 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:13:11,952 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:13:11,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:13:11,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:11,957 : INFO : EPOCH - 4 : training on 5955695 raw words (4339863 effective words) took 9.8s, 441692 effective words/s\n",
      "2019-01-16 22:13:11,961 : INFO : Opening paper FrederickDouglassPaper\n",
      "2019-01-16 22:13:12,964 : INFO : EPOCH 5 - PROGRESS: at 10.63% examples, 428610 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:13,968 : INFO : EPOCH 5 - PROGRESS: at 19.18% examples, 423087 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:14,981 : INFO : EPOCH 5 - PROGRESS: at 28.54% examples, 428843 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:15,998 : INFO : EPOCH 5 - PROGRESS: at 39.94% examples, 432137 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:17,000 : INFO : EPOCH 5 - PROGRESS: at 50.00% examples, 433290 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:18,009 : INFO : EPOCH 5 - PROGRESS: at 59.37% examples, 431895 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:19,015 : INFO : EPOCH 5 - PROGRESS: at 70.03% examples, 431929 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:20,027 : INFO : EPOCH 5 - PROGRESS: at 80.26% examples, 433750 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:21,039 : INFO : EPOCH 5 - PROGRESS: at 90.87% examples, 434695 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:21,932 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:13:21,933 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:13:21,934 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:13:21,935 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:13:21,936 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:13:21,937 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:13:21,937 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:13:21,938 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:13:21,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:13:21,944 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:21,944 : INFO : EPOCH - 5 : training on 5955695 raw words (4340440 effective words) took 10.0s, 434766 effective words/s\n",
      "2019-01-16 22:13:21,945 : INFO : training on a 29778475 raw words (21703273 effective words) took 49.7s, 436434 effective words/s\n",
      "2019-01-16 22:13:21,956 : INFO : saving Word2Vec object under FrederickDouglassPaper-w2v-model, separately None\n",
      "2019-01-16 22:13:21,957 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:13:21,958 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:13:22,206 : INFO : saved FrederickDouglassPaper-w2v-model\n"
     ]
    }
   ],
   "source": [
    "# get FrederickDouglassPaper docs into the list of list formas\n",
    "cur_paper = \"FrederickDouglassPaper\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=10) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:13:30,967 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:13:30,967 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:31,130 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:13:34,032 : INFO : collected 32478 word types from a corpus of 988768 raw words and 2047 sentences\n",
      "2019-01-16 22:13:34,033 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:13:34,057 : INFO : min_count=5 retains 11715 unique words (36% of original 32478, drops 20763)\n",
      "2019-01-16 22:13:34,058 : INFO : min_count=5 leaves 953698 word corpus (96% of original 988768, drops 35070)\n",
      "2019-01-16 22:13:34,084 : INFO : deleting the raw counts dictionary of 32478 items\n",
      "2019-01-16 22:13:34,086 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2019-01-16 22:13:34,087 : INFO : downsampling leaves estimated 694133 word corpus (72.8% of prior 953698)\n",
      "2019-01-16 22:13:34,113 : INFO : estimated required memory for 11715 words and 100 dimensions: 15229500 bytes\n",
      "2019-01-16 22:13:34,114 : INFO : resetting layer weights\n",
      "2019-01-16 22:13:34,219 : INFO : training model with 1 workers on 11715 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:13:34,221 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:35,225 : INFO : EPOCH 1 - PROGRESS: at 62.14% examples, 416333 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:35,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:35,867 : INFO : EPOCH - 1 : training on 988768 raw words (694390 effective words) took 1.6s, 421706 effective words/s\n",
      "2019-01-16 22:13:35,869 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:36,876 : INFO : EPOCH 2 - PROGRESS: at 64.78% examples, 428387 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:37,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:37,480 : INFO : EPOCH - 2 : training on 988768 raw words (694043 effective words) took 1.6s, 430938 effective words/s\n",
      "2019-01-16 22:13:37,482 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:38,491 : INFO : EPOCH 3 - PROGRESS: at 64.78% examples, 427651 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:39,091 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:39,091 : INFO : EPOCH - 3 : training on 988768 raw words (693831 effective words) took 1.6s, 431191 effective words/s\n",
      "2019-01-16 22:13:39,093 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:40,102 : INFO : EPOCH 4 - PROGRESS: at 64.78% examples, 427613 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:40,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:40,713 : INFO : EPOCH - 4 : training on 988768 raw words (694284 effective words) took 1.6s, 428495 effective words/s\n",
      "2019-01-16 22:13:40,715 : INFO : Opening paper FreedomsJournal\n",
      "2019-01-16 22:13:41,727 : INFO : EPOCH 5 - PROGRESS: at 63.61% examples, 419947 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:13:42,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:13:42,359 : INFO : EPOCH - 5 : training on 988768 raw words (693810 effective words) took 1.6s, 422290 effective words/s\n",
      "2019-01-16 22:13:42,359 : INFO : training on a 4943840 raw words (3470358 effective words) took 8.1s, 426369 effective words/s\n",
      "2019-01-16 22:13:42,366 : INFO : saving Word2Vec object under FreedomsJournal-w2v-model, separately None\n",
      "2019-01-16 22:13:42,368 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:13:42,368 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:13:42,462 : INFO : saved FreedomsJournal-w2v-model\n"
     ]
    }
   ],
   "source": [
    "cur_paper = \"FreedomsJournal\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=1) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:14:00,581 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:14:00,582 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:14:00,685 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:14:20,406 : INFO : PROGRESS: at sentence #10000, processed 11903162 words, keeping 97865 word types\n",
      "2019-01-16 22:14:39,500 : INFO : PROGRESS: at sentence #20000, processed 23444152 words, keeping 137244 word types\n",
      "2019-01-16 22:14:39,604 : INFO : collected 137484 word types from a corpus of 23511751 raw words and 20053 sentences\n",
      "2019-01-16 22:14:39,605 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:14:39,721 : INFO : min_count=5 retains 48884 unique words (35% of original 137484, drops 88600)\n",
      "2019-01-16 22:14:39,721 : INFO : min_count=5 leaves 23375641 word corpus (99% of original 23511751, drops 136110)\n",
      "2019-01-16 22:14:39,825 : INFO : deleting the raw counts dictionary of 137484 items\n",
      "2019-01-16 22:14:39,828 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2019-01-16 22:14:39,829 : INFO : downsampling leaves estimated 17746382 word corpus (75.9% of prior 23375641)\n",
      "2019-01-16 22:14:39,942 : INFO : estimated required memory for 48884 words and 100 dimensions: 63549200 bytes\n",
      "2019-01-16 22:14:39,943 : INFO : resetting layer weights\n",
      "2019-01-16 22:14:40,355 : INFO : training model with 1 workers on 48884 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:14:40,356 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:14:41,365 : INFO : EPOCH 1 - PROGRESS: at 2.43% examples, 424265 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:42,377 : INFO : EPOCH 1 - PROGRESS: at 4.89% examples, 430454 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:43,388 : INFO : EPOCH 1 - PROGRESS: at 7.49% examples, 433402 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:44,407 : INFO : EPOCH 1 - PROGRESS: at 9.86% examples, 432984 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:14:45,408 : INFO : EPOCH 1 - PROGRESS: at 12.28% examples, 435441 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:46,417 : INFO : EPOCH 1 - PROGRESS: at 14.83% examples, 437751 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:47,418 : INFO : EPOCH 1 - PROGRESS: at 17.23% examples, 437534 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:48,419 : INFO : EPOCH 1 - PROGRESS: at 19.83% examples, 436141 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:49,419 : INFO : EPOCH 1 - PROGRESS: at 22.05% examples, 435944 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:50,431 : INFO : EPOCH 1 - PROGRESS: at 24.66% examples, 437254 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:51,441 : INFO : EPOCH 1 - PROGRESS: at 27.22% examples, 438045 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:52,449 : INFO : EPOCH 1 - PROGRESS: at 29.82% examples, 438157 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:53,459 : INFO : EPOCH 1 - PROGRESS: at 32.12% examples, 438802 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:54,460 : INFO : EPOCH 1 - PROGRESS: at 34.71% examples, 439369 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:55,467 : INFO : EPOCH 1 - PROGRESS: at 36.93% examples, 439580 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:56,471 : INFO : EPOCH 1 - PROGRESS: at 39.64% examples, 439578 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:57,473 : INFO : EPOCH 1 - PROGRESS: at 42.16% examples, 439827 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:58,481 : INFO : EPOCH 1 - PROGRESS: at 44.72% examples, 440068 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:14:59,485 : INFO : EPOCH 1 - PROGRESS: at 46.83% examples, 440001 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:00,489 : INFO : EPOCH 1 - PROGRESS: at 49.25% examples, 439558 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:01,498 : INFO : EPOCH 1 - PROGRESS: at 51.83% examples, 439768 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:02,506 : INFO : EPOCH 1 - PROGRESS: at 54.60% examples, 439779 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:03,512 : INFO : EPOCH 1 - PROGRESS: at 57.26% examples, 439891 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:04,514 : INFO : EPOCH 1 - PROGRESS: at 59.81% examples, 440181 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:05,519 : INFO : EPOCH 1 - PROGRESS: at 62.55% examples, 440432 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:15:06,528 : INFO : EPOCH 1 - PROGRESS: at 65.24% examples, 440763 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:07,546 : INFO : EPOCH 1 - PROGRESS: at 67.72% examples, 440589 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:08,558 : INFO : EPOCH 1 - PROGRESS: at 70.46% examples, 440257 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:09,572 : INFO : EPOCH 1 - PROGRESS: at 73.11% examples, 439993 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:10,573 : INFO : EPOCH 1 - PROGRESS: at 75.16% examples, 439980 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:11,584 : INFO : EPOCH 1 - PROGRESS: at 77.73% examples, 439284 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:12,586 : INFO : EPOCH 1 - PROGRESS: at 80.18% examples, 439277 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:13,596 : INFO : EPOCH 1 - PROGRESS: at 82.36% examples, 438390 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:14,597 : INFO : EPOCH 1 - PROGRESS: at 85.22% examples, 438270 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:15,600 : INFO : EPOCH 1 - PROGRESS: at 87.64% examples, 438243 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:16,601 : INFO : EPOCH 1 - PROGRESS: at 90.10% examples, 438086 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:17,606 : INFO : EPOCH 1 - PROGRESS: at 92.57% examples, 437838 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:18,610 : INFO : EPOCH 1 - PROGRESS: at 94.93% examples, 437954 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:19,631 : INFO : EPOCH 1 - PROGRESS: at 97.38% examples, 437968 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:15:20,643 : INFO : EPOCH 1 - PROGRESS: at 99.86% examples, 438144 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:20,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:15:20,682 : INFO : EPOCH - 1 : training on 23511751 raw words (17671857 effective words) took 40.3s, 438231 effective words/s\n",
      "2019-01-16 22:15:20,684 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:15:21,695 : INFO : EPOCH 2 - PROGRESS: at 2.51% examples, 439675 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:22,707 : INFO : EPOCH 2 - PROGRESS: at 5.12% examples, 443489 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:23,712 : INFO : EPOCH 2 - PROGRESS: at 7.58% examples, 438281 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:15:24,728 : INFO : EPOCH 2 - PROGRESS: at 9.97% examples, 439305 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:25,732 : INFO : EPOCH 2 - PROGRESS: at 12.36% examples, 440684 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:26,741 : INFO : EPOCH 2 - PROGRESS: at 14.87% examples, 440908 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:27,751 : INFO : EPOCH 2 - PROGRESS: at 17.50% examples, 440784 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:28,772 : INFO : EPOCH 2 - PROGRESS: at 20.11% examples, 440784 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:29,776 : INFO : EPOCH 2 - PROGRESS: at 22.28% examples, 440049 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:30,780 : INFO : EPOCH 2 - PROGRESS: at 24.88% examples, 440620 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:31,797 : INFO : EPOCH 2 - PROGRESS: at 27.46% examples, 440474 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:32,808 : INFO : EPOCH 2 - PROGRESS: at 30.04% examples, 440670 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:33,819 : INFO : EPOCH 2 - PROGRESS: at 32.27% examples, 440857 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:34,822 : INFO : EPOCH 2 - PROGRESS: at 34.90% examples, 441497 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:35,830 : INFO : EPOCH 2 - PROGRESS: at 37.22% examples, 441852 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:36,833 : INFO : EPOCH 2 - PROGRESS: at 40.03% examples, 441726 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:15:37,835 : INFO : EPOCH 2 - PROGRESS: at 42.47% examples, 442090 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:15:38,858 : INFO : EPOCH 2 - PROGRESS: at 44.94% examples, 442125 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:39,861 : INFO : EPOCH 2 - PROGRESS: at 47.08% examples, 442193 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:40,863 : INFO : EPOCH 2 - PROGRESS: at 49.68% examples, 442013 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:41,876 : INFO : EPOCH 2 - PROGRESS: at 52.23% examples, 442265 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:42,893 : INFO : EPOCH 2 - PROGRESS: at 55.05% examples, 442492 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:43,905 : INFO : EPOCH 2 - PROGRESS: at 57.64% examples, 442077 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:44,911 : INFO : EPOCH 2 - PROGRESS: at 60.26% examples, 441487 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:45,916 : INFO : EPOCH 2 - PROGRESS: at 62.86% examples, 441142 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:15:46,928 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 439936 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:47,936 : INFO : EPOCH 2 - PROGRESS: at 67.63% examples, 439203 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:48,951 : INFO : EPOCH 2 - PROGRESS: at 70.46% examples, 439153 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:49,966 : INFO : EPOCH 2 - PROGRESS: at 73.13% examples, 439458 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:50,971 : INFO : EPOCH 2 - PROGRESS: at 75.31% examples, 439644 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:51,972 : INFO : EPOCH 2 - PROGRESS: at 78.04% examples, 439569 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:52,974 : INFO : EPOCH 2 - PROGRESS: at 80.38% examples, 439549 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:53,984 : INFO : EPOCH 2 - PROGRESS: at 82.81% examples, 439666 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:54,994 : INFO : EPOCH 2 - PROGRESS: at 85.54% examples, 439808 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:15:55,997 : INFO : EPOCH 2 - PROGRESS: at 88.06% examples, 440028 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:15:57,009 : INFO : EPOCH 2 - PROGRESS: at 90.59% examples, 439552 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:58,020 : INFO : EPOCH 2 - PROGRESS: at 93.10% examples, 439515 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:15:59,029 : INFO : EPOCH 2 - PROGRESS: at 95.38% examples, 439250 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:00,035 : INFO : EPOCH 2 - PROGRESS: at 97.93% examples, 439472 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:00,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:16:00,867 : INFO : EPOCH - 2 : training on 23511751 raw words (17668988 effective words) took 40.2s, 439710 effective words/s\n",
      "2019-01-16 22:16:00,869 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:16:01,883 : INFO : EPOCH 3 - PROGRESS: at 2.43% examples, 421485 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:02,896 : INFO : EPOCH 3 - PROGRESS: at 4.89% examples, 429088 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:03,898 : INFO : EPOCH 3 - PROGRESS: at 7.55% examples, 436705 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:04,908 : INFO : EPOCH 3 - PROGRESS: at 9.91% examples, 436746 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:05,917 : INFO : EPOCH 3 - PROGRESS: at 12.33% examples, 437703 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:06,937 : INFO : EPOCH 3 - PROGRESS: at 14.84% examples, 439075 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:16:07,953 : INFO : EPOCH 3 - PROGRESS: at 17.47% examples, 438983 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:08,957 : INFO : EPOCH 3 - PROGRESS: at 19.97% examples, 437267 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:09,963 : INFO : EPOCH 3 - PROGRESS: at 22.19% examples, 437818 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:10,968 : INFO : EPOCH 3 - PROGRESS: at 24.87% examples, 439938 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:11,971 : INFO : EPOCH 3 - PROGRESS: at 27.44% examples, 440329 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:12,975 : INFO : EPOCH 3 - PROGRESS: at 30.00% examples, 440392 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:13,982 : INFO : EPOCH 3 - PROGRESS: at 32.23% examples, 440558 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:14,987 : INFO : EPOCH 3 - PROGRESS: at 34.79% examples, 440522 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:15,989 : INFO : EPOCH 3 - PROGRESS: at 37.03% examples, 440100 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:16,999 : INFO : EPOCH 3 - PROGRESS: at 39.68% examples, 440131 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:18,007 : INFO : EPOCH 3 - PROGRESS: at 42.27% examples, 440232 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:19,011 : INFO : EPOCH 3 - PROGRESS: at 44.80% examples, 440577 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:20,014 : INFO : EPOCH 3 - PROGRESS: at 46.91% examples, 440394 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:21,019 : INFO : EPOCH 3 - PROGRESS: at 49.28% examples, 439906 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:22,029 : INFO : EPOCH 3 - PROGRESS: at 51.76% examples, 438709 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:23,041 : INFO : EPOCH 3 - PROGRESS: at 54.46% examples, 438516 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:24,044 : INFO : EPOCH 3 - PROGRESS: at 57.11% examples, 438358 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:25,054 : INFO : EPOCH 3 - PROGRESS: at 59.55% examples, 438195 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:26,060 : INFO : EPOCH 3 - PROGRESS: at 62.38% examples, 438655 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:27,063 : INFO : EPOCH 3 - PROGRESS: at 64.83% examples, 437720 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:28,070 : INFO : EPOCH 3 - PROGRESS: at 67.21% examples, 437866 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:29,073 : INFO : EPOCH 3 - PROGRESS: at 70.01% examples, 438250 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:30,080 : INFO : EPOCH 3 - PROGRESS: at 72.84% examples, 438427 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:31,085 : INFO : EPOCH 3 - PROGRESS: at 74.90% examples, 438359 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:32,093 : INFO : EPOCH 3 - PROGRESS: at 77.37% examples, 437960 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:33,105 : INFO : EPOCH 3 - PROGRESS: at 79.87% examples, 437804 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:34,115 : INFO : EPOCH 3 - PROGRESS: at 82.34% examples, 437923 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:35,121 : INFO : EPOCH 3 - PROGRESS: at 85.22% examples, 438151 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:36,122 : INFO : EPOCH 3 - PROGRESS: at 87.69% examples, 438521 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:37,130 : INFO : EPOCH 3 - PROGRESS: at 90.16% examples, 438275 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:38,136 : INFO : EPOCH 3 - PROGRESS: at 92.79% examples, 438713 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:39,137 : INFO : EPOCH 3 - PROGRESS: at 95.11% examples, 438580 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:40,145 : INFO : EPOCH 3 - PROGRESS: at 97.60% examples, 438562 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:41,153 : INFO : EPOCH 3 - PROGRESS: at 99.77% examples, 437625 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:41,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:16:41,265 : INFO : EPOCH - 3 : training on 23511751 raw words (17673338 effective words) took 40.4s, 437495 effective words/s\n",
      "2019-01-16 22:16:41,267 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:16:42,273 : INFO : EPOCH 4 - PROGRESS: at 2.27% examples, 404521 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:43,278 : INFO : EPOCH 4 - PROGRESS: at 4.80% examples, 422603 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:44,292 : INFO : EPOCH 4 - PROGRESS: at 7.42% examples, 429920 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:45,307 : INFO : EPOCH 4 - PROGRESS: at 9.86% examples, 434007 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:16:46,317 : INFO : EPOCH 4 - PROGRESS: at 12.32% examples, 436776 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:47,318 : INFO : EPOCH 4 - PROGRESS: at 14.80% examples, 436667 words/s, in_qsize 2, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:16:48,322 : INFO : EPOCH 4 - PROGRESS: at 17.15% examples, 435861 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:49,324 : INFO : EPOCH 4 - PROGRESS: at 19.75% examples, 434652 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:50,341 : INFO : EPOCH 4 - PROGRESS: at 21.95% examples, 432760 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:51,341 : INFO : EPOCH 4 - PROGRESS: at 24.39% examples, 432986 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:52,354 : INFO : EPOCH 4 - PROGRESS: at 26.96% examples, 431679 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:53,354 : INFO : EPOCH 4 - PROGRESS: at 29.34% examples, 432017 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:54,362 : INFO : EPOCH 4 - PROGRESS: at 31.58% examples, 431483 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:55,374 : INFO : EPOCH 4 - PROGRESS: at 33.55% examples, 425972 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:56,375 : INFO : EPOCH 4 - PROGRESS: at 35.87% examples, 424687 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:57,375 : INFO : EPOCH 4 - PROGRESS: at 38.03% examples, 423979 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:16:58,382 : INFO : EPOCH 4 - PROGRESS: at 40.66% examples, 422944 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:16:59,385 : INFO : EPOCH 4 - PROGRESS: at 42.98% examples, 423323 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:00,386 : INFO : EPOCH 4 - PROGRESS: at 45.23% examples, 423727 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:01,388 : INFO : EPOCH 4 - PROGRESS: at 47.26% examples, 423336 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:02,397 : INFO : EPOCH 4 - PROGRESS: at 49.90% examples, 423615 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:03,408 : INFO : EPOCH 4 - PROGRESS: at 52.51% examples, 424514 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:04,418 : INFO : EPOCH 4 - PROGRESS: at 55.17% examples, 425173 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:05,428 : INFO : EPOCH 4 - PROGRESS: at 57.71% examples, 425422 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:06,447 : INFO : EPOCH 4 - PROGRESS: at 60.37% examples, 425557 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:07,452 : INFO : EPOCH 4 - PROGRESS: at 63.18% examples, 426054 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:08,463 : INFO : EPOCH 4 - PROGRESS: at 65.62% examples, 426108 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:09,467 : INFO : EPOCH 4 - PROGRESS: at 67.86% examples, 425655 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:10,469 : INFO : EPOCH 4 - PROGRESS: at 70.55% examples, 425578 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:11,483 : INFO : EPOCH 4 - PROGRESS: at 73.13% examples, 425882 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:12,487 : INFO : EPOCH 4 - PROGRESS: at 75.26% examples, 426410 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:13,491 : INFO : EPOCH 4 - PROGRESS: at 77.99% examples, 426622 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:14,502 : INFO : EPOCH 4 - PROGRESS: at 80.30% examples, 426697 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:15,508 : INFO : EPOCH 4 - PROGRESS: at 82.51% examples, 426203 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:16,512 : INFO : EPOCH 4 - PROGRESS: at 85.38% examples, 426819 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:17,527 : INFO : EPOCH 4 - PROGRESS: at 87.83% examples, 427277 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:18,536 : INFO : EPOCH 4 - PROGRESS: at 90.30% examples, 427272 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:19,542 : INFO : EPOCH 4 - PROGRESS: at 92.79% examples, 427099 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:20,551 : INFO : EPOCH 4 - PROGRESS: at 95.04% examples, 426903 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:21,559 : INFO : EPOCH 4 - PROGRESS: at 97.58% examples, 427216 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:22,564 : INFO : EPOCH 4 - PROGRESS: at 99.85% examples, 427237 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:22,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:17:22,622 : INFO : EPOCH - 4 : training on 23511751 raw words (17671650 effective words) took 41.4s, 427309 effective words/s\n",
      "2019-01-16 22:17:22,624 : INFO : Opening paper GodeysLadysBook\n",
      "2019-01-16 22:17:23,628 : INFO : EPOCH 5 - PROGRESS: at 2.38% examples, 419917 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:24,640 : INFO : EPOCH 5 - PROGRESS: at 4.89% examples, 431029 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:25,646 : INFO : EPOCH 5 - PROGRESS: at 7.49% examples, 434503 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:26,664 : INFO : EPOCH 5 - PROGRESS: at 9.86% examples, 433915 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:27,679 : INFO : EPOCH 5 - PROGRESS: at 12.16% examples, 430978 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:28,684 : INFO : EPOCH 5 - PROGRESS: at 14.58% examples, 428398 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:29,696 : INFO : EPOCH 5 - PROGRESS: at 16.92% examples, 427044 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:30,713 : INFO : EPOCH 5 - PROGRESS: at 19.49% examples, 428404 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:31,724 : INFO : EPOCH 5 - PROGRESS: at 21.89% examples, 429420 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:32,729 : INFO : EPOCH 5 - PROGRESS: at 24.32% examples, 430513 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:33,738 : INFO : EPOCH 5 - PROGRESS: at 26.96% examples, 430642 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:34,754 : INFO : EPOCH 5 - PROGRESS: at 29.18% examples, 428391 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:35,759 : INFO : EPOCH 5 - PROGRESS: at 31.42% examples, 427139 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:36,763 : INFO : EPOCH 5 - PROGRESS: at 33.68% examples, 426395 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:37,764 : INFO : EPOCH 5 - PROGRESS: at 36.08% examples, 427338 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:38,776 : INFO : EPOCH 5 - PROGRESS: at 38.65% examples, 428155 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:39,776 : INFO : EPOCH 5 - PROGRESS: at 41.35% examples, 429490 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:40,780 : INFO : EPOCH 5 - PROGRESS: at 43.80% examples, 430010 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:41,783 : INFO : EPOCH 5 - PROGRESS: at 46.00% examples, 430723 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:42,793 : INFO : EPOCH 5 - PROGRESS: at 48.30% examples, 431125 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:43,801 : INFO : EPOCH 5 - PROGRESS: at 51.09% examples, 430952 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:44,803 : INFO : EPOCH 5 - PROGRESS: at 53.42% examples, 431197 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:45,825 : INFO : EPOCH 5 - PROGRESS: at 56.05% examples, 430738 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:46,828 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 431059 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:47,828 : INFO : EPOCH 5 - PROGRESS: at 61.15% examples, 430566 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:48,828 : INFO : EPOCH 5 - PROGRESS: at 63.91% examples, 430152 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:49,843 : INFO : EPOCH 5 - PROGRESS: at 66.16% examples, 430644 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:50,855 : INFO : EPOCH 5 - PROGRESS: at 68.89% examples, 431139 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:51,864 : INFO : EPOCH 5 - PROGRESS: at 71.78% examples, 431259 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:52,879 : INFO : EPOCH 5 - PROGRESS: at 73.93% examples, 431514 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:53,880 : INFO : EPOCH 5 - PROGRESS: at 76.37% examples, 431590 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:54,885 : INFO : EPOCH 5 - PROGRESS: at 78.74% examples, 432070 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:55,894 : INFO : EPOCH 5 - PROGRESS: at 81.52% examples, 432141 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:56,906 : INFO : EPOCH 5 - PROGRESS: at 84.01% examples, 432428 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:17:57,920 : INFO : EPOCH 5 - PROGRESS: at 86.69% examples, 432244 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:17:58,934 : INFO : EPOCH 5 - PROGRESS: at 89.07% examples, 432097 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:17:59,945 : INFO : EPOCH 5 - PROGRESS: at 91.57% examples, 432465 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:18:00,950 : INFO : EPOCH 5 - PROGRESS: at 93.88% examples, 432717 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:18:01,955 : INFO : EPOCH 5 - PROGRESS: at 96.50% examples, 432795 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:18:02,971 : INFO : EPOCH 5 - PROGRESS: at 99.01% examples, 432977 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-16 22:18:03,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:18:03,417 : INFO : EPOCH - 5 : training on 23511751 raw words (17671731 effective words) took 40.8s, 433201 effective words/s\n",
      "2019-01-16 22:18:03,418 : INFO : training on a 117558755 raw words (88357564 effective words) took 203.1s, 435122 effective words/s\n",
      "2019-01-16 22:18:03,421 : INFO : saving Word2Vec object under GodeysLadysBook-w2v-model, separately None\n",
      "2019-01-16 22:18:03,422 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:18:03,423 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:18:03,917 : INFO : saved GodeysLadysBook-w2v-model\n"
     ]
    }
   ],
   "source": [
    "cur_paper = \"GodeysLadysBook\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=1) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:18:20,188 : INFO : collecting all words and their counts\n",
      "2019-01-16 22:18:20,189 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:18:20,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-16 22:18:58,271 : INFO : collected 117261 word types from a corpus of 21251210 raw words and 8905 sentences\n",
      "2019-01-16 22:18:58,272 : INFO : Loading a fresh vocabulary\n",
      "2019-01-16 22:18:58,386 : INFO : min_count=5 retains 43767 unique words (37% of original 117261, drops 73494)\n",
      "2019-01-16 22:18:58,386 : INFO : min_count=5 leaves 21134645 word corpus (99% of original 21251210, drops 116565)\n",
      "2019-01-16 22:18:58,481 : INFO : deleting the raw counts dictionary of 117261 items\n",
      "2019-01-16 22:18:58,484 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2019-01-16 22:18:58,485 : INFO : downsampling leaves estimated 15688728 word corpus (74.2% of prior 21134645)\n",
      "2019-01-16 22:18:58,585 : INFO : estimated required memory for 43767 words and 100 dimensions: 56897100 bytes\n",
      "2019-01-16 22:18:58,585 : INFO : resetting layer weights\n",
      "2019-01-16 22:18:58,937 : INFO : training model with 10 workers on 43767 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-16 22:18:58,940 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:18:59,943 : INFO : EPOCH 1 - PROGRESS: at 2.93% examples, 450237 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:00,947 : INFO : EPOCH 1 - PROGRESS: at 5.72% examples, 455683 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:01,952 : INFO : EPOCH 1 - PROGRESS: at 8.71% examples, 458127 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:02,966 : INFO : EPOCH 1 - PROGRESS: at 11.65% examples, 457272 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:03,973 : INFO : EPOCH 1 - PROGRESS: at 14.89% examples, 455280 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:04,988 : INFO : EPOCH 1 - PROGRESS: at 18.01% examples, 455446 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:05,993 : INFO : EPOCH 1 - PROGRESS: at 20.70% examples, 454427 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:07,005 : INFO : EPOCH 1 - PROGRESS: at 23.35% examples, 454625 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:08,017 : INFO : EPOCH 1 - PROGRESS: at 26.85% examples, 454923 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:09,023 : INFO : EPOCH 1 - PROGRESS: at 29.49% examples, 454977 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:10,031 : INFO : EPOCH 1 - PROGRESS: at 32.51% examples, 454196 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:11,031 : INFO : EPOCH 1 - PROGRESS: at 35.22% examples, 449074 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:12,041 : INFO : EPOCH 1 - PROGRESS: at 38.08% examples, 449346 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:13,058 : INFO : EPOCH 1 - PROGRESS: at 41.02% examples, 449351 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:14,060 : INFO : EPOCH 1 - PROGRESS: at 43.99% examples, 450013 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:15,070 : INFO : EPOCH 1 - PROGRESS: at 47.61% examples, 450465 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:16,077 : INFO : EPOCH 1 - PROGRESS: at 50.60% examples, 450680 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:17,083 : INFO : EPOCH 1 - PROGRESS: at 53.49% examples, 450380 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:18,083 : INFO : EPOCH 1 - PROGRESS: at 56.59% examples, 450728 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:19,090 : INFO : EPOCH 1 - PROGRESS: at 58.91% examples, 448859 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:20,103 : INFO : EPOCH 1 - PROGRESS: at 61.91% examples, 447875 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:21,103 : INFO : EPOCH 1 - PROGRESS: at 64.88% examples, 448575 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:22,116 : INFO : EPOCH 1 - PROGRESS: at 67.91% examples, 448665 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:23,123 : INFO : EPOCH 1 - PROGRESS: at 70.54% examples, 448470 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:24,124 : INFO : EPOCH 1 - PROGRESS: at 73.37% examples, 448376 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:25,133 : INFO : EPOCH 1 - PROGRESS: at 76.33% examples, 448496 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:26,140 : INFO : EPOCH 1 - PROGRESS: at 79.05% examples, 448606 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:27,150 : INFO : EPOCH 1 - PROGRESS: at 82.20% examples, 448935 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:28,161 : INFO : EPOCH 1 - PROGRESS: at 85.35% examples, 449283 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:29,166 : INFO : EPOCH 1 - PROGRESS: at 87.85% examples, 449519 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:30,180 : INFO : EPOCH 1 - PROGRESS: at 90.74% examples, 449595 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:31,188 : INFO : EPOCH 1 - PROGRESS: at 93.79% examples, 449635 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:32,189 : INFO : EPOCH 1 - PROGRESS: at 97.16% examples, 449273 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:33,210 : INFO : EPOCH 1 - PROGRESS: at 99.89% examples, 449062 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:33,233 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:19:33,235 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:19:33,236 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:19:33,237 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:19:33,238 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:19:33,240 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:19:33,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:19:33,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:19:33,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:19:33,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:19:33,248 : INFO : EPOCH - 1 : training on 21251210 raw words (15413459 effective words) took 34.3s, 449269 effective words/s\n",
      "2019-01-16 22:19:33,252 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:19:34,262 : INFO : EPOCH 2 - PROGRESS: at 2.92% examples, 439913 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:35,268 : INFO : EPOCH 2 - PROGRESS: at 5.67% examples, 446397 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:36,283 : INFO : EPOCH 2 - PROGRESS: at 8.66% examples, 448738 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:37,285 : INFO : EPOCH 2 - PROGRESS: at 11.47% examples, 452057 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:38,300 : INFO : EPOCH 2 - PROGRESS: at 14.85% examples, 450324 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:19:39,308 : INFO : EPOCH 2 - PROGRESS: at 17.82% examples, 447954 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:40,308 : INFO : EPOCH 2 - PROGRESS: at 20.51% examples, 448049 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:41,322 : INFO : EPOCH 2 - PROGRESS: at 23.08% examples, 448590 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:42,336 : INFO : EPOCH 2 - PROGRESS: at 26.50% examples, 449016 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:43,343 : INFO : EPOCH 2 - PROGRESS: at 29.31% examples, 450337 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:44,345 : INFO : EPOCH 2 - PROGRESS: at 32.33% examples, 451724 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:45,350 : INFO : EPOCH 2 - PROGRESS: at 35.53% examples, 450849 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:46,356 : INFO : EPOCH 2 - PROGRESS: at 38.26% examples, 451309 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:47,364 : INFO : EPOCH 2 - PROGRESS: at 41.21% examples, 451452 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:48,366 : INFO : EPOCH 2 - PROGRESS: at 44.26% examples, 452122 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:49,373 : INFO : EPOCH 2 - PROGRESS: at 47.91% examples, 452392 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:50,376 : INFO : EPOCH 2 - PROGRESS: at 50.90% examples, 452955 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:19:51,378 : INFO : EPOCH 2 - PROGRESS: at 53.80% examples, 453151 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:52,389 : INFO : EPOCH 2 - PROGRESS: at 56.96% examples, 453673 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:53,400 : INFO : EPOCH 2 - PROGRESS: at 59.52% examples, 453847 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:19:54,420 : INFO : EPOCH 2 - PROGRESS: at 63.03% examples, 454106 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:55,433 : INFO : EPOCH 2 - PROGRESS: at 65.54% examples, 454212 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:56,438 : INFO : EPOCH 2 - PROGRESS: at 68.61% examples, 454209 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:57,441 : INFO : EPOCH 2 - PROGRESS: at 71.48% examples, 454406 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:58,455 : INFO : EPOCH 2 - PROGRESS: at 74.35% examples, 453953 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:19:59,460 : INFO : EPOCH 2 - PROGRESS: at 77.17% examples, 453912 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:00,476 : INFO : EPOCH 2 - PROGRESS: at 79.81% examples, 453345 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:01,483 : INFO : EPOCH 2 - PROGRESS: at 83.19% examples, 453697 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:02,487 : INFO : EPOCH 2 - PROGRESS: at 86.10% examples, 453883 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:03,494 : INFO : EPOCH 2 - PROGRESS: at 88.94% examples, 454256 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:04,495 : INFO : EPOCH 2 - PROGRESS: at 91.40% examples, 454203 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:05,504 : INFO : EPOCH 2 - PROGRESS: at 95.06% examples, 454379 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:06,515 : INFO : EPOCH 2 - PROGRESS: at 97.92% examples, 453567 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:07,208 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:20:07,209 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:20:07,210 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:20:07,210 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:20:07,212 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:20:07,212 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:20:07,214 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:20:07,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:20:07,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:20:07,220 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:20:07,221 : INFO : EPOCH - 2 : training on 21251210 raw words (15415781 effective words) took 34.0s, 453832 effective words/s\n",
      "2019-01-16 22:20:07,226 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:20:08,229 : INFO : EPOCH 3 - PROGRESS: at 2.85% examples, 435588 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:09,238 : INFO : EPOCH 3 - PROGRESS: at 5.59% examples, 439341 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:10,253 : INFO : EPOCH 3 - PROGRESS: at 8.52% examples, 443650 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:11,269 : INFO : EPOCH 3 - PROGRESS: at 11.31% examples, 444758 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:20:12,280 : INFO : EPOCH 3 - PROGRESS: at 14.63% examples, 444925 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:13,289 : INFO : EPOCH 3 - PROGRESS: at 17.77% examples, 445681 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:14,294 : INFO : EPOCH 3 - PROGRESS: at 20.38% examples, 445576 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:15,296 : INFO : EPOCH 3 - PROGRESS: at 22.77% examples, 445331 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:16,306 : INFO : EPOCH 3 - PROGRESS: at 26.37% examples, 445442 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:17,313 : INFO : EPOCH 3 - PROGRESS: at 28.97% examples, 445087 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:18,318 : INFO : EPOCH 3 - PROGRESS: at 31.84% examples, 445174 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:19,327 : INFO : EPOCH 3 - PROGRESS: at 34.79% examples, 443295 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:20,327 : INFO : EPOCH 3 - PROGRESS: at 37.65% examples, 443412 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:21,330 : INFO : EPOCH 3 - PROGRESS: at 40.67% examples, 444129 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:22,355 : INFO : EPOCH 3 - PROGRESS: at 43.53% examples, 444745 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:23,358 : INFO : EPOCH 3 - PROGRESS: at 47.06% examples, 446343 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:24,359 : INFO : EPOCH 3 - PROGRESS: at 50.16% examples, 446992 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:25,371 : INFO : EPOCH 3 - PROGRESS: at 53.16% examples, 446984 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:26,371 : INFO : EPOCH 3 - PROGRESS: at 56.11% examples, 446599 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:27,378 : INFO : EPOCH 3 - PROGRESS: at 58.64% examples, 445963 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:28,383 : INFO : EPOCH 3 - PROGRESS: at 61.37% examples, 445203 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:29,388 : INFO : EPOCH 3 - PROGRESS: at 64.33% examples, 444447 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:30,390 : INFO : EPOCH 3 - PROGRESS: at 67.19% examples, 444674 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:31,391 : INFO : EPOCH 3 - PROGRESS: at 69.97% examples, 444790 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:32,399 : INFO : EPOCH 3 - PROGRESS: at 72.80% examples, 445030 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:33,422 : INFO : EPOCH 3 - PROGRESS: at 75.77% examples, 445334 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:34,424 : INFO : EPOCH 3 - PROGRESS: at 78.67% examples, 445842 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:35,432 : INFO : EPOCH 3 - PROGRESS: at 81.49% examples, 445972 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:36,437 : INFO : EPOCH 3 - PROGRESS: at 84.60% examples, 446288 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:37,437 : INFO : EPOCH 3 - PROGRESS: at 87.19% examples, 445646 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:38,449 : INFO : EPOCH 3 - PROGRESS: at 90.14% examples, 445908 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:39,454 : INFO : EPOCH 3 - PROGRESS: at 92.98% examples, 445810 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:40,465 : INFO : EPOCH 3 - PROGRESS: at 96.50% examples, 446069 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:41,491 : INFO : EPOCH 3 - PROGRESS: at 99.10% examples, 446023 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:41,748 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:20:41,749 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:20:41,750 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:20:41,750 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:20:41,751 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:20:41,752 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:20:41,753 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:20:41,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:20:41,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:20:41,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:20:41,760 : INFO : EPOCH - 3 : training on 21251210 raw words (15415917 effective words) took 34.5s, 446391 effective words/s\n",
      "2019-01-16 22:20:41,765 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:20:42,775 : INFO : EPOCH 4 - PROGRESS: at 2.93% examples, 447062 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:43,779 : INFO : EPOCH 4 - PROGRESS: at 5.74% examples, 455626 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:44,781 : INFO : EPOCH 4 - PROGRESS: at 8.71% examples, 457511 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:20:45,804 : INFO : EPOCH 4 - PROGRESS: at 11.65% examples, 455771 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-16 22:20:46,810 : INFO : EPOCH 4 - PROGRESS: at 14.87% examples, 453016 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:47,811 : INFO : EPOCH 4 - PROGRESS: at 17.93% examples, 452394 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:48,812 : INFO : EPOCH 4 - PROGRESS: at 20.62% examples, 451772 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:49,812 : INFO : EPOCH 4 - PROGRESS: at 23.17% examples, 452171 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:50,826 : INFO : EPOCH 4 - PROGRESS: at 26.69% examples, 452954 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:51,828 : INFO : EPOCH 4 - PROGRESS: at 29.40% examples, 454192 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:52,833 : INFO : EPOCH 4 - PROGRESS: at 32.50% examples, 454485 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:53,834 : INFO : EPOCH 4 - PROGRESS: at 35.78% examples, 455232 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:54,836 : INFO : EPOCH 4 - PROGRESS: at 38.53% examples, 455288 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:55,839 : INFO : EPOCH 4 - PROGRESS: at 41.46% examples, 455300 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:56,847 : INFO : EPOCH 4 - PROGRESS: at 44.55% examples, 455943 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:57,867 : INFO : EPOCH 4 - PROGRESS: at 48.16% examples, 455975 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:58,871 : INFO : EPOCH 4 - PROGRESS: at 51.02% examples, 455804 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:20:59,876 : INFO : EPOCH 4 - PROGRESS: at 54.07% examples, 456028 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:00,883 : INFO : EPOCH 4 - PROGRESS: at 57.05% examples, 455675 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:01,900 : INFO : EPOCH 4 - PROGRESS: at 59.52% examples, 454027 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:02,902 : INFO : EPOCH 4 - PROGRESS: at 62.72% examples, 453303 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:03,909 : INFO : EPOCH 4 - PROGRESS: at 65.39% examples, 452786 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:04,911 : INFO : EPOCH 4 - PROGRESS: at 68.34% examples, 453022 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:05,928 : INFO : EPOCH 4 - PROGRESS: at 71.14% examples, 452804 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:06,937 : INFO : EPOCH 4 - PROGRESS: at 74.15% examples, 453216 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:07,937 : INFO : EPOCH 4 - PROGRESS: at 76.95% examples, 453696 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:08,939 : INFO : EPOCH 4 - PROGRESS: at 79.72% examples, 453734 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:09,952 : INFO : EPOCH 4 - PROGRESS: at 83.09% examples, 453667 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:10,959 : INFO : EPOCH 4 - PROGRESS: at 86.05% examples, 454230 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:11,967 : INFO : EPOCH 4 - PROGRESS: at 88.94% examples, 454796 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:12,977 : INFO : EPOCH 4 - PROGRESS: at 91.40% examples, 454590 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:13,988 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 454163 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:15,011 : INFO : EPOCH 4 - PROGRESS: at 97.92% examples, 453737 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:15,701 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:21:15,703 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:21:15,703 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:21:15,704 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:21:15,705 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:21:15,706 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:21:15,707 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:21:15,708 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:21:15,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:21:15,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:21:15,715 : INFO : EPOCH - 4 : training on 21251210 raw words (15413889 effective words) took 33.9s, 454027 effective words/s\n",
      "2019-01-16 22:21:15,718 : INFO : Opening paper NationalAntiSlaveryStandard\n",
      "2019-01-16 22:21:16,725 : INFO : EPOCH 5 - PROGRESS: at 2.93% examples, 449046 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:17,727 : INFO : EPOCH 5 - PROGRESS: at 5.74% examples, 457189 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:18,737 : INFO : EPOCH 5 - PROGRESS: at 8.74% examples, 459631 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:19,740 : INFO : EPOCH 5 - PROGRESS: at 11.70% examples, 459374 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:20,741 : INFO : EPOCH 5 - PROGRESS: at 14.95% examples, 458157 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:21,748 : INFO : EPOCH 5 - PROGRESS: at 18.18% examples, 457866 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:22,766 : INFO : EPOCH 5 - PROGRESS: at 20.74% examples, 456842 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:23,772 : INFO : EPOCH 5 - PROGRESS: at 23.58% examples, 458663 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:24,779 : INFO : EPOCH 5 - PROGRESS: at 27.06% examples, 458613 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:25,784 : INFO : EPOCH 5 - PROGRESS: at 29.65% examples, 459204 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:26,792 : INFO : EPOCH 5 - PROGRESS: at 32.84% examples, 459646 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:27,801 : INFO : EPOCH 5 - PROGRESS: at 36.20% examples, 459816 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:28,832 : INFO : EPOCH 5 - PROGRESS: at 38.96% examples, 458980 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:21:29,833 : INFO : EPOCH 5 - PROGRESS: at 41.98% examples, 459765 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:30,845 : INFO : EPOCH 5 - PROGRESS: at 45.26% examples, 459895 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:31,854 : INFO : EPOCH 5 - PROGRESS: at 48.66% examples, 459758 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:32,856 : INFO : EPOCH 5 - PROGRESS: at 51.59% examples, 459919 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:33,871 : INFO : EPOCH 5 - PROGRESS: at 54.74% examples, 459477 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:34,872 : INFO : EPOCH 5 - PROGRESS: at 57.44% examples, 458862 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:35,874 : INFO : EPOCH 5 - PROGRESS: at 60.29% examples, 458980 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:36,877 : INFO : EPOCH 5 - PROGRESS: at 63.60% examples, 459255 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:37,883 : INFO : EPOCH 5 - PROGRESS: at 66.22% examples, 459261 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:38,888 : INFO : EPOCH 5 - PROGRESS: at 69.19% examples, 458870 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:39,898 : INFO : EPOCH 5 - PROGRESS: at 72.03% examples, 458831 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:40,906 : INFO : EPOCH 5 - PROGRESS: at 75.12% examples, 458854 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:41,911 : INFO : EPOCH 5 - PROGRESS: at 78.03% examples, 458707 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:42,923 : INFO : EPOCH 5 - PROGRESS: at 80.76% examples, 458666 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:43,939 : INFO : EPOCH 5 - PROGRESS: at 84.14% examples, 458460 words/s, in_qsize 0, out_qsize 1\n",
      "2019-01-16 22:21:44,942 : INFO : EPOCH 5 - PROGRESS: at 86.87% examples, 458656 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:45,954 : INFO : EPOCH 5 - PROGRESS: at 89.67% examples, 458729 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:46,957 : INFO : EPOCH 5 - PROGRESS: at 92.58% examples, 458528 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:47,987 : INFO : EPOCH 5 - PROGRESS: at 96.16% examples, 458426 words/s, in_qsize 0, out_qsize 0\n",
      "2019-01-16 22:21:49,001 : INFO : EPOCH 5 - PROGRESS: at 98.98% examples, 458100 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 22:21:49,351 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-01-16 22:21:49,352 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-01-16 22:21:49,352 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-16 22:21:49,353 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-16 22:21:49,354 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-16 22:21:49,355 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-16 22:21:49,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-16 22:21:49,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-16 22:21:49,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-16 22:21:49,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-16 22:21:49,364 : INFO : EPOCH - 5 : training on 21251210 raw words (15416426 effective words) took 33.6s, 458212 effective words/s\n",
      "2019-01-16 22:21:49,365 : INFO : training on a 106256050 raw words (77075472 effective words) took 170.4s, 452246 effective words/s\n",
      "2019-01-16 22:21:49,374 : INFO : saving Word2Vec object under NationalAntiSlaveryStandard-w2v-model, separately None\n",
      "2019-01-16 22:21:49,375 : INFO : not storing attribute vectors_norm\n",
      "2019-01-16 22:21:49,376 : INFO : not storing attribute cum_table\n",
      "2019-01-16 22:21:49,822 : INFO : saved NationalAntiSlaveryStandard-w2v-model\n"
     ]
    }
   ],
   "source": [
    "cur_paper = \"NationalAntiSlaveryStandard\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=10) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LK TO HERE TODAY\n",
    "cur_paper = \"ProvincialFreeman\"\n",
    "articles = MyArticles(base_dir, cur_paper)\n",
    "\n",
    "# build vocab and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    articles,\n",
    "    min_count=5, # default is 5; this trims the corpus for words only used once; up to 100 is OK \n",
    "    size=100, # size of NN layers; default is 100; higher for larger corpora\n",
    "    workers=10) # parallel processing; needs Cython\n",
    "\n",
    "# save model\n",
    "model.save(cur_paper + \"-w2v-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.9999532699584961),\n",
       " ('most', 0.9999502897262573),\n",
       " ('against', 0.9999476671218872),\n",
       " ('with', 0.9999455213546753),\n",
       " ('like', 0.9999449253082275),\n",
       " ('without', 0.9999438524246216),\n",
       " ('among', 0.9999430179595947),\n",
       " ('being', 0.9999424815177917),\n",
       " ('into', 0.9999416470527649),\n",
       " ('an', 0.999941349029541)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing some basic functions\n",
    "\n",
    "# basic similarity\n",
    "w1 = \"freedom\"\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998831061190858"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two word similarity \n",
    "\n",
    "model.wv.similarity(w1=\"freedom\",w2=\"justice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974367023618899"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"freedom\",w2=\"abolition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996274907535606"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"freedom\",w2=\"emancipation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9145890133346956"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"freedom\",w2=\"liberation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 0.9811407923698425),\n",
       " ('you', 0.980480432510376),\n",
       " ('mentioned', 0.9800600409507751),\n",
       " ('us', 0.9799489974975586),\n",
       " ('beach', 0.979884147644043),\n",
       " ('have', 0.9798733592033386),\n",
       " ('would', 0.9797930717468262),\n",
       " ('information', 0.979749858379364),\n",
       " ('taught', 0.979706883430481),\n",
       " ('longer', 0.9796891212463379)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opposite words\n",
    "model.wv.most_similar(positive=[\"freedom\",\"emancipation\"], negative=[\"slavery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
