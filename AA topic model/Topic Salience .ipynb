{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of file w/ topic counts\n",
    "count_file = \"allpapers-topics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv into pandas dataframe\n",
    "\n",
    "df = pd.read_csv(count_file)\n",
    "    \n",
    "# csv has header row in format \"Title\" then each topic number 0-99\n",
    "# each subesequent row is in format newspaper title, t00-proportion, t02-proportion etc.\n",
    "# each row totals the number of articles in corpus of that paper\n",
    "# each column totals the proportion of that topic in corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need function to determine total number of docs in df\n",
    "# total_docs = # need code to sum each row, and then sum each of those sums\n",
    "\n",
    "def all_topics_by_paper(paper):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Title'] == paper:\n",
    "            return int(row['Total'])\n",
    "        \n",
    "# testing\n",
    "all_topics_by_paper('DouglassMonthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321.018576845"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topic_in_all_papers(topic):\n",
    "    # need function to determine total number of articles assoc. w/ topic, given topic \n",
    "    # just add the column of that topic\n",
    "    return df[topic].sum()\n",
    "\n",
    "# testing\n",
    "topic_in_all_papers('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to calculate total docs in corpus for total_docs\n",
    "total_docs = int(df['Total'].sum())\n",
    "\n",
    "# salience functions \n",
    "def topic_freq(topic, paper):\n",
    "    # this one calculates the \"number\" of times a topic appears in a newspaper, \n",
    "    # normalized by dividing by the total \"number\" of topics in the paper \n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Title'] == paper:\n",
    "            topic_score = row[topic]\n",
    "            return topic_score / all_topics_by_paper(paper)  \n",
    "\n",
    "def inv_paper_freq(topic): \n",
    "    # This one measures how common a topic is among all newpaper articles in the corpus. \n",
    "    # The more common a topic is, the lower its \"ipf.\"\" I take the ratio of the total\n",
    "    # number of newspaper articles to the number of articles containing the topic, then \n",
    "    # take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "    \n",
    "    return math.log(total_docs / (1 + topic_in_all_papers(topic)))\n",
    "\n",
    "def tfipf(topic, paper):\n",
    "    # just the product of the \"TF\" and \"IPF\"\n",
    "    return topic_freq(topic, paper) * inv_paper_freq(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372276\n",
      "0.007701160209668025\n",
      "4.719062911416954\n",
      "0.036342259520324396\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(total_docs)\n",
    "\n",
    "print(topic_freq('0', 'DouglassMonthly'))\n",
    "\n",
    "print(inv_paper_freq('0'))\n",
    "\n",
    "print(tfipf('0', 'DouglassMonthly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each newspaper, calculate tf-ipf score for each topic\n",
    "# then print top 10 topics for each paper \n",
    "\n",
    "fout = open(\"tf-ipf.txt\",\"w\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # calculate scores and store to dict\n",
    "    scores = {}\n",
    "    for i in range(0,99):\n",
    "        scores[i] = tfipf(str(i), row['Title'])\n",
    "    \n",
    "    print(\"=== TF-IPF Scores for\",row['Title'], \"===\", file=fout)\n",
    "    # then sort dict by highest tfipf score and print / write to file\n",
    "    \n",
    "    for key, value in sorted(scores.items(), key=lambda kv: kv[1], reverse=True):\n",
    "        print(key, round(value, 4), file=fout)\n",
    "\n",
    "    print(file=fout)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
